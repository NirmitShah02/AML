{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copy of VSK_Ensemble.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndxk_kMeSUfn"
      },
      "source": [
        "### Implementation of Ensemble Learning Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky8BY1RmSUfy"
      },
      "source": [
        "![](ensemble_learning.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HNdIFBSSUfz"
      },
      "source": [
        "# Performance of Weak Learners"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "461Gj9ugSUf0"
      },
      "source": [
        "# A weak learner is a model that may have errors."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf9vfPmmSUf1"
      },
      "source": [
        "# We are Importing some libraries to build the models\n",
        "\n",
        "import numpy as np # use for numerical operations\n",
        "import pandas as pd # use for dataframe\n",
        "\n",
        "# Here we are imporing classifiers libraries\n",
        "from sklearn.tree import DecisionTreeClassifier # Decision Tree classifier\n",
        "from sklearn.linear_model import LogisticRegression # Logistic Regression\n",
        "from sklearn.svm import SVC # Support Vector Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier # KNN Classifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72qmYnDySUf5",
        "outputId": "292285a6-cb58-4fe5-9b03-5bb8c4365646"
      },
      "source": [
        "#Reading the dataset\n",
        "dataset = pd.read_csv('Ensemble.csv')\n",
        "\n",
        "print(dataset)\n",
        "\n",
        "# We have update the dataset by puting some incomplete or missing informations.\n",
        "# Those are represented by NaN (Not a Number) or Null values."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Height (in cms)  Weight (in kgs) T Shirt Size\n",
            "0             158.0             58.0            M\n",
            "1             158.0             59.0            M\n",
            "2             158.0             63.0            M\n",
            "3             160.0             59.0            M\n",
            "4             160.0             60.0            M\n",
            "5             189.0              NaN            M\n",
            "6             100.0             67.0          NaN\n",
            "7             168.0             66.0            L\n",
            "8             170.0             63.0            L\n",
            "9             170.0             64.0            L\n",
            "10            200.0              NaN            M\n",
            "11            210.0             89.0          NaN\n",
            "12            163.0             60.0            M\n",
            "13            163.0             61.0            M\n",
            "14            160.0             64.0            L\n",
            "15            163.0             64.0            L\n",
            "16            165.0             61.0            L\n",
            "17            163.0              NaN          NaN\n",
            "18            165.0             61.0          NaN\n",
            "19              NaN             64.0          NaN\n",
            "20            168.0              NaN            L\n",
            "21            165.0             62.0            L\n",
            "22            165.0             65.0            L\n",
            "23            168.0             62.0            L\n",
            "24            168.0             63.0            L\n",
            "25              NaN             67.0            L\n",
            "26            210.0              NaN            M\n",
            "27              NaN             89.0            L\n",
            "28            170.0             68.0            L\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-0ZnUC5SUf7",
        "outputId": "eb1dcb2e-27f8-4f47-b136-f33e9a1d3bcb"
      },
      "source": [
        "# You can know the size of the dataset the by the following syntax\n",
        "dataset.shape # 29 29 Rows and 03 columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiKpxWreSUf9",
        "outputId": "5aba2de9-a4fb-4099-ac1c-a32f42903f7a"
      },
      "source": [
        "# In this dataset we have incomplete or missing information\n",
        "# we need to remove those rows and columns which are having NaN.\n",
        "# We can use dropna () method to drop null values based rows and columns\n",
        "\n",
        "# drop all rows with any NaN values\n",
        "\n",
        "ds1 = dataset.dropna()\n",
        "print(ds1)\n",
        "\n",
        "# ds1 is complete dataset which are not having by any NaN value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Height (in cms)  Weight (in kgs) T Shirt Size\n",
            "0             158.0             58.0            M\n",
            "1             158.0             59.0            M\n",
            "2             158.0             63.0            M\n",
            "3             160.0             59.0            M\n",
            "4             160.0             60.0            M\n",
            "7             168.0             66.0            L\n",
            "8             170.0             63.0            L\n",
            "9             170.0             64.0            L\n",
            "12            163.0             60.0            M\n",
            "13            163.0             61.0            M\n",
            "14            160.0             64.0            L\n",
            "15            163.0             64.0            L\n",
            "16            165.0             61.0            L\n",
            "21            165.0             62.0            L\n",
            "22            165.0             65.0            L\n",
            "23            168.0             62.0            L\n",
            "24            168.0             63.0            L\n",
            "28            170.0             68.0            L\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ig3AWzeSUf-",
        "outputId": "1ecd81ab-f1a3-45e9-8cec-43d70b1ea016"
      },
      "source": [
        "# Let us check total number of rows in correct or without null values into updated dataset\n",
        "ds1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4KhukzGSUgD",
        "outputId": "cf8ccfb7-7060-4723-c8f8-cf8aefc34514"
      },
      "source": [
        "# There are two ways to make your dataset as complete \n",
        "# 1. To remove NaN or null values (DS1)\n",
        "# 2. To replace some values instead of NaN values (DS2)\n",
        "\n",
        "# fill the values using forward fill (ffill) method \n",
        "# meaning that the value NaN will be updated by or replaced by its previous or upper value\n",
        "ds2 = dataset.fillna (method = 'ffill')\n",
        "print (ds2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Height (in cms)  Weight (in kgs) T Shirt Size\n",
            "0             158.0             58.0            M\n",
            "1             158.0             59.0            M\n",
            "2             158.0             63.0            M\n",
            "3             160.0             59.0            M\n",
            "4             160.0             60.0            M\n",
            "5             189.0             60.0            M\n",
            "6             100.0             67.0            M\n",
            "7             168.0             66.0            L\n",
            "8             170.0             63.0            L\n",
            "9             170.0             64.0            L\n",
            "10            200.0             64.0            M\n",
            "11            210.0             89.0            M\n",
            "12            163.0             60.0            M\n",
            "13            163.0             61.0            M\n",
            "14            160.0             64.0            L\n",
            "15            163.0             64.0            L\n",
            "16            165.0             61.0            L\n",
            "17            163.0             61.0            L\n",
            "18            165.0             61.0            L\n",
            "19            165.0             64.0            L\n",
            "20            168.0             64.0            L\n",
            "21            165.0             62.0            L\n",
            "22            165.0             65.0            L\n",
            "23            168.0             62.0            L\n",
            "24            168.0             63.0            L\n",
            "25            168.0             67.0            L\n",
            "26            210.0             67.0            M\n",
            "27            210.0             89.0            L\n",
            "28            170.0             68.0            L\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8bGaSG1SUgJ",
        "outputId": "28449275-3207-43a6-bc89-929378100355"
      },
      "source": [
        "# Dataset variable contains the data including NaN values\n",
        "# DS1- A dataset variable which does not contain NaN value\n",
        "# DS2- A dataset variable which is using all rows and columns by filling or updating NaN values\n",
        "\n",
        "ds2.shape \n",
        "# Now the dataset ds2 contains no null or NaN values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYItChwoSUgK",
        "outputId": "5c2bed8f-a463-47c6-fef2-c48cc512ffbc"
      },
      "source": [
        "# DS1- 18 rows\n",
        "# DS2- 29 rows without NaN values\n",
        "\n",
        "ds2.columns\n",
        "# ds2 is our updated or filter based dataset \n",
        "# while dataset variable contains all data along with NaN values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Height (in cms)', 'Weight (in kgs)', 'T Shirt Size'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOQcleviSUgL",
        "outputId": "c28005a1-414b-4dd5-afd3-9534a7fd3c17"
      },
      "source": [
        "X = ds2.iloc[:, [0, 1]].values # Independent variable (Height and weight)\n",
        "y = ds2.iloc[:, 2].values # Dependent variable or target class (T-Shirt Size)\n",
        "\n",
        "print (X)\n",
        "print (y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[158.  58.]\n",
            " [158.  59.]\n",
            " [158.  63.]\n",
            " [160.  59.]\n",
            " [160.  60.]\n",
            " [189.  60.]\n",
            " [100.  67.]\n",
            " [168.  66.]\n",
            " [170.  63.]\n",
            " [170.  64.]\n",
            " [200.  64.]\n",
            " [210.  89.]\n",
            " [163.  60.]\n",
            " [163.  61.]\n",
            " [160.  64.]\n",
            " [163.  64.]\n",
            " [165.  61.]\n",
            " [163.  61.]\n",
            " [165.  61.]\n",
            " [165.  64.]\n",
            " [168.  64.]\n",
            " [165.  62.]\n",
            " [165.  65.]\n",
            " [168.  62.]\n",
            " [168.  63.]\n",
            " [168.  67.]\n",
            " [210.  67.]\n",
            " [210.  89.]\n",
            " [170.  68.]]\n",
            "['M' 'M' 'M' 'M' 'M' 'M' 'M' 'L' 'L' 'L' 'M' 'M' 'M' 'M' 'L' 'L' 'L' 'L'\n",
            " 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'M' 'L' 'L']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of962J02SUgO",
        "outputId": "077c29e2-ef05-4114-a257-939ebcdb0908"
      },
      "source": [
        "# As we know that our T-Shirt Size values are non-integer and if we need to perform some \n",
        "# mathematical Calculations as per need, so we have to transform the non-integer values \n",
        "# into integer values\n",
        "\n",
        "# This will encode your non-integer values into integer values\n",
        "\n",
        "# Import LabelEncoder class from preprocessing library from sklearn package\n",
        "#from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#creating labelEncoder\n",
        "le = LabelEncoder() # le is an object of labelencoder class\n",
        "\n",
        "# By defauly we have values in M/L of Y variable\n",
        "y_new = y # now y_new will contain m/l\n",
        "\n",
        "#y_new is variable for transformed values\n",
        "# Converting string labels into numbers\n",
        "y_new=le.fit_transform(y_new) # passing the T-Shirt Size values (M/L) which is represented by y variable\n",
        "\n",
        "# we are replacing y actual values into 0 and 1.\n",
        "\n",
        "print (y) # values in M/L\n",
        "\n",
        "print(y_new) # now y variable will contain information in 0 and 1.\n",
        "\n",
        "# 1 means M and 0 means L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['M' 'M' 'M' 'M' 'M' 'M' 'M' 'L' 'L' 'L' 'M' 'M' 'M' 'M' 'L' 'L' 'L' 'L'\n",
            " 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'M' 'L' 'L']\n",
            "[1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5ieFpY3SUgP"
      },
      "source": [
        "# we have transformed our M/L values into 1 and 0\n",
        "# Now update y variable by updated values\n",
        "\n",
        "y = y_new # we are replacing y values by 0 and 1 using y_new variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr6ZTZJfSUgP"
      },
      "source": [
        "# So far prepared dataset and transformed non-interger values to integer values\n",
        "# Next step is to split your dataset into training and testing\n",
        "\n",
        "# We are Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.45, random_state = 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSjivUgsSUgQ",
        "outputId": "0cb9db2f-df56-419c-b893-c498dfc1a330"
      },
      "source": [
        "print (X_train.shape) # size of the training data\n",
        "print (X_test.shape) # Size of the testing data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15, 2)\n",
            "(14, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILawRxNaSUgR"
      },
      "source": [
        "# Now we are building our models\n",
        "\n",
        "# Here we are imporing classifiers libraries\n",
        "from sklearn.tree import DecisionTreeClassifier # Decision Tree classifier\n",
        "from sklearn.linear_model import LogisticRegression # Logistic Regression\n",
        "from sklearn.svm import SVC # Support Vector Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier # KNN Classifier\n",
        "\n",
        "#Defining the machine learning models by creating their objects\n",
        "model1 = LogisticRegression()\n",
        "model2 = DecisionTreeClassifier(max_depth = 5)\n",
        "# 21 would be total nodes in a decision tree\n",
        "# max_depth = depth of tree based on 21 nodes\n",
        "model3 = SVC()\n",
        "model4 = KNeighborsClassifier(n_neighbors = 6, metric = 'euclidean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6jcRfrwSUgR",
        "outputId": "fe7ba209-e943-4dbd-c8e0-7bb4447ec91c"
      },
      "source": [
        "# We need to fit the models towards the training dataset\n",
        "#Training the machine learning models\n",
        "model1.fit(X_train, y_train) # LR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SBo8Q2vSUgT",
        "outputId": "51302296-af48-49d8-c226-e75880c894b3"
      },
      "source": [
        "model2.fit(X_train, y_train) # DTC\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAKhrGMvSUgU",
        "outputId": "7f0c4e13-1e04-43b2-fd19-392ef91ce35e"
      },
      "source": [
        "model3.fit(X_train, y_train) # SVC\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ws3IOD4SUgV",
        "outputId": "b47c7118-c16a-470d-da02-1c398af69c62"
      },
      "source": [
        "model4.fit(X_train, y_train) # KNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(metric='euclidean', n_neighbors=6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v32v0f2iSUgW"
      },
      "source": [
        "# We are predicting by using testing dataset\n",
        "#Making the prediction\n",
        "y_pred1 = model1.predict(X_test) # LR\n",
        "y_pred2 = model2.predict(X_test) # DTC\n",
        "y_pred3 = model3.predict(X_test) # SVC\n",
        "y_pred4 = model4.predict(X_test) # KNN\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK-3217xSUgW",
        "outputId": "39af5251-d2da-47e2-dadb-3cef3da2d18b"
      },
      "source": [
        "print (\"Actual values of the testing data: \", y_test)\n",
        "print (\"Prediction by LR:\", y_pred1)\n",
        "print (\"Prediction by DT:\", y_pred2)\n",
        "print (\"Prediction by SVC:\", y_pred3)\n",
        "print (\"Prediction by KNN:\", y_pred4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual values of the testing data:  [0 0 0 0 0 0 0 0 0 0 1 1 1 1]\n",
            "Prediction by LR: [1 1 1 1 1 1 1 1 1 1 0 0 0 1]\n",
            "Prediction by DT: [0 0 1 0 1 0 0 0 1 0 1 1 1 1]\n",
            "Prediction by SVC: [1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Prediction by KNN: [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB-gx6qSSUgX"
      },
      "source": [
        "# We are Confusion Matric to measure the performance models\n",
        "#Confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm_LogisticRegression = confusion_matrix(y_test, y_pred1)\n",
        "cm_DecisionTree = confusion_matrix(y_test, y_pred2)\n",
        "cm_SupportVectorClass = confusion_matrix(y_test, y_pred3)\n",
        "cm_KNN = confusion_matrix(y_test, y_pred4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJFEzZTcSUgY",
        "outputId": "ca61f05e-9887-4d81-bfeb-341d647fc8a5"
      },
      "source": [
        "print (cm_LogisticRegression)\n",
        "print (cm_DecisionTree)\n",
        "print (cm_SupportVectorClass)\n",
        "print (cm_KNN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0 10]\n",
            " [ 3  1]]\n",
            "[[7 3]\n",
            " [0 4]]\n",
            "[[ 0 10]\n",
            " [ 0  4]]\n",
            "[[10  0]\n",
            " [ 3  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztT8BW0aSUgY",
        "outputId": "c9ece3e8-2316-4f19-bfe6-9669477068e7"
      },
      "source": [
        "# When we need to calculate the accuracy of the model under classification \n",
        "# always use testing dataset to get the result\n",
        "\n",
        "# we are measuring the performance of the model by accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#accuracy scores\n",
        "log_acc = accuracy_score(y_pred1, y_test) #(prediction value , actual value)\n",
        "dt_acc = accuracy_score(y_pred2, y_test)\n",
        "svm_acc = accuracy_score(y_pred3, y_test)\n",
        "knn_acc = accuracy_score(y_pred4, y_test)\n",
        "\n",
        "print (\"Accuracy of Logistic Regression Model in %:\",log_acc*100)\n",
        "print (\"Accuracy of Decision Tree Model in %:\",dt_acc*100)\n",
        "print(\"Accuracy of Support Vector Machine Model in %:\",svm_acc*100)\n",
        "print(\"Accuracy of KNN Model in %:\",knn_acc*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Logistic Regression Model in %: 7.142857142857142\n",
            "Accuracy of Decision Tree Model in %: 78.57142857142857\n",
            "Accuracy of Support Vector Machine Model in %: 28.57142857142857\n",
            "Accuracy of KNN Model in %: 78.57142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJvHFKH8SUgZ"
      },
      "source": [
        "# The model which does have accuracy score less than 100%, it means the model contains some errors and\n",
        "# this is the reason it it known as weak learner model.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ko-d9_mSUgZ"
      },
      "source": [
        "### Ensemble Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO2COzSNSUga"
      },
      "source": [
        "### In this work, we have defined each of the four machine learning models 5 times that results in a combination of a total of (4 ML models x 5 times)=20 weak learners. Then finally, then Max Voting Classifier method is used where the class which has been predicted mostly by the weak learners will be the final class prediction of the ensemble model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3Itbb2_SUga",
        "outputId": "3cbfdeb7-5497-40d3-8986-07656d239707"
      },
      "source": [
        "# Defining Hybrid (becuase we have 4 differet models) Ensemble Learning Model\n",
        "# means we are aggregating all 4 models as a one group (Ensemble)\n",
        "# create the sub-models\n",
        "\n",
        "estimators = []\n",
        "# estimators is a variable and it contains or append all the models details in a list.\n",
        "\n",
        "# Defining 5 Logistic Regression Models\n",
        "# model11, model12, model13, model14, model15 are the objects of the LR\n",
        "model11 = LogisticRegression()\n",
        "estimators.append(('logistic1', model11))\n",
        "model12 = LogisticRegression()\n",
        "estimators.append(('logistic2', model12))\n",
        "model13 = LogisticRegression()\n",
        "estimators.append(('logistic3', model13))\n",
        "model14 = LogisticRegression()\n",
        "estimators.append(('logistic4', model14))\n",
        "model15 = LogisticRegression()\n",
        "estimators.append(('logistic5', model15))\n",
        "\n",
        "# Printing the values of the estimators\n",
        "estimators"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('logistic1', LogisticRegression()),\n",
              " ('logistic2', LogisticRegression()),\n",
              " ('logistic3', LogisticRegression()),\n",
              " ('logistic4', LogisticRegression()),\n",
              " ('logistic5', LogisticRegression())]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eh3In_wSUgb",
        "outputId": "5da020ba-c422-4e52-fec8-b9a90e8aebe7"
      },
      "source": [
        "# Defining 5 Decision Tree Classifiers\n",
        "\n",
        "# CART = Classification and Regression Technique\n",
        "\n",
        "# Decision tree is the best example of CART becuase it supports the both approaches \n",
        "# on the same datasets at the same time.\n",
        "\n",
        "model16 = DecisionTreeClassifier(max_depth = 4)\n",
        "estimators.append(('cart1', model16))\n",
        "model17 = DecisionTreeClassifier(max_depth = 3)\n",
        "estimators.append(('cart2', model17))\n",
        "model18 = DecisionTreeClassifier(max_depth = 6)\n",
        "estimators.append(('cart3', model18))\n",
        "model19 = DecisionTreeClassifier(max_depth = 7)\n",
        "estimators.append(('cart4', model19))\n",
        "model20 = DecisionTreeClassifier(max_depth = 2)\n",
        "estimators.append(('cart5', model20))\n",
        "\n",
        "estimators"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('logistic1', LogisticRegression()),\n",
              " ('logistic2', LogisticRegression()),\n",
              " ('logistic3', LogisticRegression()),\n",
              " ('logistic4', LogisticRegression()),\n",
              " ('logistic5', LogisticRegression()),\n",
              " ('cart1', DecisionTreeClassifier(max_depth=4)),\n",
              " ('cart2', DecisionTreeClassifier(max_depth=3)),\n",
              " ('cart3', DecisionTreeClassifier(max_depth=6)),\n",
              " ('cart4', DecisionTreeClassifier(max_depth=7)),\n",
              " ('cart5', DecisionTreeClassifier(max_depth=2))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYR1o_nXSUgb",
        "outputId": "632c298c-6226-4169-e924-24fc8139c0a9"
      },
      "source": [
        "#Defining 5 Support Vector Classifiers\n",
        "model21 = SVC(kernel = 'linear')\n",
        "estimators.append(('svm1', model21))\n",
        "model22 = SVC(kernel = 'poly')\n",
        "estimators.append(('svm2', model22))\n",
        "model23 = SVC(kernel = 'rbf')\n",
        "estimators.append(('svm3', model23))\n",
        "model24 = SVC(kernel = 'rbf')\n",
        "estimators.append(('svm4', model24))\n",
        "model25 = SVC(kernel = 'linear')\n",
        "estimators.append(('svm5', model25))\n",
        "\n",
        "estimators\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('logistic1', LogisticRegression()),\n",
              " ('logistic2', LogisticRegression()),\n",
              " ('logistic3', LogisticRegression()),\n",
              " ('logistic4', LogisticRegression()),\n",
              " ('logistic5', LogisticRegression()),\n",
              " ('cart1', DecisionTreeClassifier(max_depth=4)),\n",
              " ('cart2', DecisionTreeClassifier(max_depth=3)),\n",
              " ('cart3', DecisionTreeClassifier(max_depth=6)),\n",
              " ('cart4', DecisionTreeClassifier(max_depth=7)),\n",
              " ('cart5', DecisionTreeClassifier(max_depth=2)),\n",
              " ('svm1', SVC(kernel='linear')),\n",
              " ('svm2', SVC(kernel='poly')),\n",
              " ('svm3', SVC()),\n",
              " ('svm4', SVC()),\n",
              " ('svm5', SVC(kernel='linear'))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvcpiDq-SUgc",
        "outputId": "fd312a6d-cc74-4621-fe85-6a789c85768c"
      },
      "source": [
        "#Defining 5 K-NN classifiers\n",
        "model26 = KNeighborsClassifier(n_neighbors = 3, metric = 'euclidean')\n",
        "estimators.append(('knn1', model26))\n",
        "model27 = KNeighborsClassifier(n_neighbors = 5, metric = 'euclidean')\n",
        "estimators.append(('knn2', model27))\n",
        "model28 = KNeighborsClassifier(n_neighbors = 6, metric = 'euclidean')\n",
        "estimators.append(('knn3', model28))\n",
        "model29 = KNeighborsClassifier(n_neighbors = 4, metric = 'euclidean')\n",
        "estimators.append(('knn4', model29))\n",
        "model30 = KNeighborsClassifier(n_neighbors = 7, metric = 'euclidean')\n",
        "estimators.append(('knn5', model30))\n",
        "\n",
        "estimators\n",
        "\n",
        "# At the last estimators contains the all the models details in terms of their objects values\n",
        "# ans it stores the detail in a group (list type variable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('logistic1', LogisticRegression()),\n",
              " ('logistic2', LogisticRegression()),\n",
              " ('logistic3', LogisticRegression()),\n",
              " ('logistic4', LogisticRegression()),\n",
              " ('logistic5', LogisticRegression()),\n",
              " ('cart1', DecisionTreeClassifier(max_depth=4)),\n",
              " ('cart2', DecisionTreeClassifier(max_depth=3)),\n",
              " ('cart3', DecisionTreeClassifier(max_depth=6)),\n",
              " ('cart4', DecisionTreeClassifier(max_depth=7)),\n",
              " ('cart5', DecisionTreeClassifier(max_depth=2)),\n",
              " ('svm1', SVC(kernel='linear')),\n",
              " ('svm2', SVC(kernel='poly')),\n",
              " ('svm3', SVC()),\n",
              " ('svm4', SVC()),\n",
              " ('svm5', SVC(kernel='linear')),\n",
              " ('knn1', KNeighborsClassifier(metric='euclidean', n_neighbors=3)),\n",
              " ('knn2', KNeighborsClassifier(metric='euclidean')),\n",
              " ('knn3', KNeighborsClassifier(metric='euclidean', n_neighbors=6)),\n",
              " ('knn4', KNeighborsClassifier(metric='euclidean', n_neighbors=4)),\n",
              " ('knn5', KNeighborsClassifier(metric='euclidean', n_neighbors=7))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7sAm20SSUgd",
        "outputId": "437bed7e-2cf4-4f63-92e4-347e2459ea19"
      },
      "source": [
        "# At the last we need to ensemble or aggregate our models by using estimators variable\n",
        "# and fit the new model with estimators variable\n",
        "\n",
        "# Defining the ensemble model\n",
        "\n",
        "# Here we are using votingclassifier because it is basic ensemble learning model\n",
        "# others are bagging classifier (Random Forest) and boosing classifier(ADABOOST)\n",
        "\n",
        "# Here we are not able to use Random Forest classifier \n",
        "# because all models must be followed by decision trees\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# we need to pass an estimator variable and that must contain all the models as our desire\n",
        "ensemble = VotingClassifier(estimators) \n",
        "\n",
        "# Like the other models we need to fit the ensemble model with same training dataset\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# we need to predict the ensemble model like others with same testing dataset\n",
        "y_pred = ensemble.predict(X_test)\n",
        "\n",
        "print (y_test) # actual values of testing data\n",
        "print (y_pred) # predicted values by the ensemble model using voting classifier "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 0 1 0 0 0 1 0 1 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgJHMsHZSUgd",
        "outputId": "77b72c8e-f233-4471-fc02-7e9823e66947"
      },
      "source": [
        "#Confisuin matrix\n",
        "cm_Ensembler = confusion_matrix(y_test, y_pred)\n",
        "cm_Ensembler\n",
        "\n",
        "# You can note that the confusion matrix of this ensemble model is same as logistic regression model\n",
        "# because the five learners of the logistic regression are giving maximum vote for accuracy.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7, 3],\n",
              "       [1, 3]], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy-OzqV7SUge"
      },
      "source": [
        "acc = accuracy_score(y_pred, y_test) # prediction value of Ensemble model and Actual testing value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPoWJAnuSUge",
        "outputId": "0abd2da8-6821-494d-bfcb-6530d0192fde"
      },
      "source": [
        "# We are displaying the accuracy of the our defined ensemble learning model (VotingClassier)\n",
        "acc*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71.42857142857143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRCABlC7SUgf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_19kj768SUgf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}